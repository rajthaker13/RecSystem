# -*- coding: utf-8 -*-
"""SampleRec

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iXT30nIqiyjRDTBtPzY6wRGNcvcd8DdY
"""

from typing import Any, Union, List
import pandas as pd
import numpy as np
import pip
from pandas import Series, DataFrame
from pandas.core.arrays import ExtensionArray
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
import requests
from google.colab import files
import matplotlib.pyplot as plt
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from scipy import sparse
import seaborn as sns

#datafileID:1BrOgf9tsVnDhbROxcvUibBaAzgOmBAFO
!pip install PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)
downloaded = drive.CreateFile({'id':"1BrOgf9tsVnDhbROxcvUibBaAzgOmBAFO"})   
downloaded.GetContentFile('final.csv')    
download1 = drive.CreateFile({})   



#Pre-processing
data = pd.read_csv('final.csv')
data['age'].fillna(' ', inplace = True)
data['sex'].replace('Male', 0, inplace = True)
data['sex'].replace('Female', 1, inplace= True)
#print(data)

!pip install youtube_transcript_api
from youtube_transcript_api import YouTubeTranscriptApi

#Merging data for each patient into patient info + url of videos watchrd
last_patient_id = 26207
similar_patients = data
for i, text in enumerate(data['patient_id']): 
  if data['patient_id'][i] == last_patient_id:
    if i > 0:
      similar_patients['url'][i] =  similar_patients['url'][i-1] + " " + similar_patients['url'][i]
      similar_patients.drop([i-1], inplace = True)
  else:
    last_patient_id = data['patient_id'][i]

#print(similar_patients)


#cosine similarity

#Convert to matrix
count = CountVectorizer()
count_matrix = count.fit_transform(similar_patients).astype(float)

chunk_size = 50
matrix_len = count_matrix.shape[0]
norm_count = count_matrix.astype(np.float16)

def similarity_cosine_by_chunk(start, end):
  if end > matrix_len:
    end = matrix_len
  return cosine_similarity(X = norm_count[start:end], Y = norm_count, dense_output = False)

cosine_similarity_data = []
i = 0
s = 0
for chunk_start in range(0, matrix_len, chunk_size):
  #should we use 20
  if s % 20 == 0:
    print(s)
  if i == 0:
    cosine_sim = similarity_cosine_by_chunk(chunk_start, chunk_start + chunk_size)

  else:
    cosine_similarity_chunk = similarity_cosine_by_chunk(chunk_start, chunk_start + chunk_size)
    cosine_sim = sparse.vstack((cosine_sim.astype(np.float16), cosine_similarity_chunk.astype(np.float16)))


  i = 1
  s = s + 1




#function to find similar patients
index_patients = pd.Series(similar_patients.index)


def similar_users(id, cosine_sim = cosine_sim):
  similar_users = []
  index_patients_input = index_patients[index_patients == id].index[0]
  similar_score = pd.Series(np.squeeze(np.asarray(cosine_sim.astype('float32').todense()[index_patients_input]))).sort_values(ascending = False)
  top_5_patients = list(similar_score.iloc[1:6].index)
  for i in top_5_patients:
    similar_users.append(similar_patients['patient_id'].iloc[i])

  return similar_users

print(similar_users(26207))



























#patient_info1[[“patient_id”, “age”, “sex”, “has_bh_specialist”]]
#define function to merge videos watches for each user



"""# New Section"""